# -*- coding: utf-8 -*-
"""Temperatura MLP_Regressão.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MqfN0mo5z8JWACt2ec54P84lXU8kQacw
"""

from keras.models import Sequential
from keras.layers import Dense
from sklearn.datasets import make_regression
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import StandardScaler
from numpy import array
from sklearn.model_selection import train_test_split
from keras import optimizers
from tensorflow.keras.optimizers import Adam
import matplotlib.pyplot as plt
import numpy as np
from sklearn.metrics import mean_squared_error, r2_score
import pandas as pd

#inserindo o dataset
df = pd.read_csv('DailyDelhiClimateTrain.csv')

#df = ['Open','High','Low','Adj Close','Volume']

#removendo valores null
#df = df.dropna()

df.head()

#saida do modelo
y = df['meantemp'].values
#valores de entrada
X = df.drop(columns = ['date', 'meantemp'])

#normalização dos valores de X
sc = StandardScaler()
sc.fit(X)
X = sc.transform(X)

#normalização dos valores de Y
scalarY = MinMaxScaler()
scalarY.fit(y.reshape(X.shape[0],1))
y = scalarY.transform(y.reshape(X.shape[0],1))

# difine x_scaler
x_scaler = MinMaxScaler()
M = x_scaler.fit_transform(X.reshape(-1, 1))
N = x_scaler.fit(X.reshape(-1, 1))
print(M)

#divisão dos dados de treino e teste
X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.1)

import tensorflow as tf
# define o modelo

def neural(X_train):
    model = Sequential()
    model.add(Dense(200, input_dim=X.shape[1], activation='relu'))
    model.add(Dense(300, activation='relu'))

    model.add(Dense(1, activation='linear'))
    return model

#execução da rede
model = neural(X_train)
adam = tf.keras.optimizers.Adam(learning_rate=0.0001)
model.compile(loss='mse', optimizer=adam)
history = model.fit(X_train, Y_train, epochs=500, verbose=1, validation_data=(X_test,Y_test))

#plot do erro do treino e validação dos dados
prediction = model.predict(X_test)
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()

#plot dos dados preditos
plt.scatter(Y_test, prediction)
plt.xlabel('True Values')
plt.ylabel('Predictions')
plt.axis('equal')
plt.axis('square')
plt.xlim([0,plt.xlim()[1]])
plt.ylim([0,plt.ylim()[1]])
_ = plt.plot([-100, 100], [-100, 100])

#erro quadratico médio
a = prediction-Y_test
rmse = np.sqrt(np.power(np.sum(a),2)/a.shape[0])
print('Raiz do Erro medio quadratico = '+str(rmse))

r2 = r2_score(Y_test, prediction)
print(r2)

y = scalarY.inverse_transform(prediction)
y_teste = scalarY.inverse_transform(Y_test)
print(y-y_teste)